---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Hi, welcome to my website! I am Qingyan Guo (ÈÉ≠Ê∏ÖÂ¶ç), a 2nd-year master's student majoring in Artificial Intelligence at Tsinghua University, Shenzhen International Graduate School, supervised by [Prof. Yujiu Yang](https://sites.google.com/view/iigroup-thu/home). My current research interests mainly include large language models, prompt learning, etc.

Prior to that, I did my undergrad at Tianjin University, where I double-majored in Computer Science and English Literature.

# Experiences

## Education

- Summer Intern, √âcole Polytechnique F√©d√©rale de Lausanne ([EPFL](https://www.epfl.ch/en/)), Jun. 2024 - Present
- Master student, Artificial Intelligence, Tsinghua University, Sept. 2022 - Jul. 2025 (Expected)
- Bachelor of Engineering, Computer Science, Tianjin University, Sept. 2018 - Jul. 2022
- Bachelor of Art, English Literature (double major), Tianjin University, Sept. 2020 - Jul. 2022

## Internships

<head>  
  <style>  
    table, th, td {  
      border: 0;  
    }  
  </style>  
</head>

<table style="width:100%;border:0;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
        <tr>
            <td  style="padding:20px;width:20%;vertical-align:middle">
                <img width="130" src="/images/epfl_logo.png">
            </td>
            <td style="margin-left:20px;width:80%;vertical-align:middle">
                <div >
                    Summer Intern, , <a href="https://brbiclab.epfl.ch/">Brbic Lab</a>
                </div>
                Jun. 2024 - Present <br>
                Advisor: <a href="https://cs.stanford.edu/~mbrbic/">Maria Brbic</a>, <a href="https://shawnfan19.github.io/">Shawn Fan</a><br>
                Interests: Multi-modal single-cell foundation model
            </td>
        </tr>
        <tr>
            <td  style="padding:20px;width:20%;vertical-align:middle">
                <img width="130" src="/images/ms_logo.png">
            </td>
            <td style="margin-left:20px;width:80%;vertical-align:middle">
                <div >
                    Research Intern, Machine Learning Group, <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">MicroSoft Research Asia</a>
                Beijing, China</div>
                Jan. 2023 - Present <br>
                Advisor: <a href="https://scholar.google.com/citations?user=h1IrWikAAAAJ&hl=zh-CN&oi=ao">Rui Wang</a>, <a href="https://tan-xu.github.io/">Xu Tan</a><br>
                Interests: Prompt Learning, Machine Translation
            </td>
        </tr>
        <tr>
            <td  style="padding:20px;width:20%;vertical-align:middle">
                <img width="130" src="/images/baidu_logo.png">
            </td>
            <td style="margin-left:20px;width:80%;vertical-align:middle">
                <div >
                    MLE Intern, General Dialogue Group, Baidu Inc., Beijing, China
                </div>
                Mar. 2022 - Dec. 2022 <br>
                Advisor: Zeyang Lei <br>
                Interests: Dialogue Generation, Persona for Users
            </td>
        </tr>
        <tr>
            <td  style="padding:20px;width:20%;vertical-align:middle">
                <img width="130" src="/images/didi_logo.png">
            </td>
            <td style="margin-left:20px;width:80%;vertical-align:middle">
                <div >
                    MLE Intern, Marketplace Technology, Didi Inc., Beijing, China
                </div>
                Nov. 2021 - Mar. 2022 <br>
                Interests: Causal Inference, Time Series Forecasting
            </td>
        </tr>
    </tbody>
</table>

## Competitions

(Nov. 2022) 1st Place (1/54) in NLP task of [NeurIPS 2022 IGLU Challenge](https://www.aicrowd.com/challenges/neurips-2022-iglu-challenge)

# Publications

- [**ACL 2024 Findings**] Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training [[paper](https://arxiv.org/abs/2403.00758)] [[code](https://github.com/beeevita/SPT)]<br>**Qingyan Guo**\*, Rui Wang, Junliang Guo, Xu Tan, Jiang Bian, Yujiu Yang<br> <small>This work explores reversal curse which exists among many decoder-only large language models and poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models' ability to comprehend and apply bidirectional reasoning. To address this issue, we propose Semantic-aware Permutation Training (SPT), by segmenting the training sentences into semantic units (i.e., entities or phrases) with an assistant language model and permuting these units before feeding into the model. SPT effectively mitigates the reversal curse of LLMs.</small>
- [**ICLR  2024**] Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers [[paper](https://arxiv.org/abs/2309.08532)] [[code](https://github.com/beeevita/EvoPrompt)]<br>**Qingyan Guo**\*, Rui Wang\*, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang<br> <small>This work proposes EvoPrompt, leveraging the strong natural language genetion capabilities of LLMs, as well as the efficient optimization performance of evolution algorithms. Without access to any internal parameters or gradients, EvoPrompt significantly outperforms human-engineered prompts and existing methods for automatic prompt generation.</small>
- [**ICASSP 2023**] Hint-enhanced In-Context Learning wakes Large Language Models up for knowledge-intensive tasks [[paper](https://arxiv.org/abs/2311.01949)]
  <br>Yifan Wang, **Qingyan Guo**, Xinzhe Ni, Chufan Shi, Lemao Liu, Haiyun Jiang, Yujiu Yang<br> <small>This work proposes a new paradigm called Hint-enhanced In-Context Learning (HICL) to leveraging LLMs' reasoning ability to extract query-related knowledge from demonstrations, to better elicit ICL ability of LLMs.
- [**ACL 2023 Main**] MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction [[paper](https://arxiv.org/abs/2305.12627)] [[code](https://github.com/ZubinGou/multi-view-prompting)]<br>Zhibin Gou\*, **Qingyan Guo**\*, Yujiu Yang<br><small>This work proposes MvP, a simple unified generative framework for structure prediction to leverage the intuition of human-like problem-solving processes from different views. MvP achieves state-of-the-art performance on 10 datasets across 4 ABSA tasks.</small>

# Honors

- Outstanding Graduate, 2022
- Outstanding Graduate Thesis, 2022
- National Scholarship, 2020
- Tianjin Municipal Government Scholarship, 2021
- Outstanding Youth, 2021
- ...

# Personal Interests

I love music üéµ (R&B, popular), singing üé§ (popular music), coffee ‚òïÔ∏è and I spend most of my spare time on them! Feel free to contact me if you are interested too!

 <div style="display: flex; align-items: center; justify-content: center;">
    <img src="images/image1.jpg" style="width:25%; margin: 0; height: 260px"><img src="images/image3.jpg" style="width:25%; margin: 0; height: 260px"><img src="images/image4.jpg" style="width:25%; margin: 0;height: 260px"><img src="images/image2.jpg" style="width:25%; margin: 0; height: 260px">
</div>

<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=0eHSe6-orAFVpUKZokMFuyObeBwgrjfXFgcRyB--78Q&cl=ffffff&w=a"></script> -->

<center>To be continued...</center>
